{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVULETm5bYGrRI99LoK14y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustineJa/OC_IMLP5/blob/Embedding/IML_P5_Embedding_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import des packages, fonctions et paramétrage initial"
      ],
      "metadata": {
        "id": "OHBfeZSkrrH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texthero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Jc4aqAw6FC",
        "outputId": "02e254cd-d75d-4954-ceeb-d02ae73dcc16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting texthero\n",
            "  Downloading texthero-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from texthero) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from texthero) (1.2.2)\n",
            "Collecting spacy<3.0.0 (from texthero)\n",
            "  Downloading spacy-2.3.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.10/dist-packages (from texthero) (4.66.2)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.10/dist-packages (from texthero) (3.8.1)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from texthero) (5.15.0)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from texthero) (1.5.3)\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from texthero) (1.9.3)\n",
            "Collecting unidecode>=1.1.1 (from texthero)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim<4.0,>=3.6.0 (from texthero)\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from texthero) (3.7.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.11.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<4.0,>=3.6.0->texthero) (6.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.3->texthero) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.3->texthero) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.3->texthero) (2023.12.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.2->texthero) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.2.0->texthero) (8.2.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->texthero) (3.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spacy<3.0.0->texthero)\n",
            "  Downloading thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spacy<3.0.0->texthero)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spacy<3.0.0->texthero)\n",
            "  Downloading srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.2/369.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy<3.0.0->texthero)\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (67.7.2)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spacy<3.0.0->texthero)\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.0.0->texthero) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2024.2.2)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: Could not build wheels for gensim, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nOFLTxWLrl2p"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Modules classiques d'analyse exploratoire:\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement du datasets"
      ],
      "metadata": {
        "id": "l57-mB_4r1fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_7m73wyrxGR",
        "outputId": "f2a21290-f35b-4320-aaae-a6a6229579bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création des DataFrame\n",
        "df_stack = pd.read_csv(\"/content/drive/MyDrive/2_Formations/2.0_OpenClassRooms/2.0.0_IML/IML P5/5.1_Data/QueryResults.csv\")\n",
        "df_stack.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "yeBK0ZwJr4sq",
        "outputId": "4f3b1571-60be-4566-ab94-879dc11aa312"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Title  \\\n",
              "0  Python kernel dies for second run of PyQt5 GUI   \n",
              "\n",
              "                                                Body  \\\n",
              "0  <ul>\\n<li>Using Spyder in Python 3.5.2 |Anacon...   \n",
              "\n",
              "                                         Tags         CreationDate  \\\n",
              "0  <python><ipython><anaconda><pyqt5><spyder>  2016-10-17 19:21:55   \n",
              "\n",
              "   AnswerCount  ViewCount  Score  \n",
              "0            3      10077     17  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61a45659-54aa-46cc-9f3f-cb14298eb907\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>AnswerCount</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Python kernel dies for second run of PyQt5 GUI</td>\n",
              "      <td>&lt;ul&gt;\\n&lt;li&gt;Using Spyder in Python 3.5.2 |Anacon...</td>\n",
              "      <td>&lt;python&gt;&lt;ipython&gt;&lt;anaconda&gt;&lt;pyqt5&gt;&lt;spyder&gt;</td>\n",
              "      <td>2016-10-17 19:21:55</td>\n",
              "      <td>3</td>\n",
              "      <td>10077</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61a45659-54aa-46cc-9f3f-cb14298eb907')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61a45659-54aa-46cc-9f3f-cb14298eb907 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61a45659-54aa-46cc-9f3f-cb14298eb907');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_stack",
              "summary": "{\n  \"name\": \"df_stack\",\n  \"rows\": 35018,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35018,\n        \"samples\": [\n          \"Error: write EPIPE with node.js and imagemagick\",\n          \"nginx: connect() failed (111: Connection refused) while connecting to upstream\",\n          \"Create new column based on values from other columns / apply a function of multiple columns, row-wise in Pandas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35018,\n        \"samples\": [\n          \"<p>I'm lost as to where this error is coming from, and I'm hoping you can help me. I'm new to node and am trying to resize an image with imagemagick:</p>\\n\\n<pre><code>var express = require('express'), \\nfs = require('fs'),\\ngm = require('gm'),\\nimagemagick = require('imagemagick'),\\nvar gm = require('gm').subClass({ imageMagick: true });\\nvar app = express();\\n\\n\\napp.get('/', function (req, res) {\\n    console.log(__dirname + \\\"/public/photos/4af1e720-a662-11e3-952c-61812ab60f67.jpg\\\");\\n    imagemagick.resize({\\n           srcData: fs.readFileSync(__dirname + \\\"/public/photos/4af1e720-a662-11e3-952c-61812ab60f67.jpg\\\", 'binary'),\\n           width: \\\"400\\\"\\n    }, function(err,stdout,stderr){\\n           if (err) console.log(err);\\n           fs.writeFile(__dirname + \\\"/public/photos/thumbnail/4af1e720-a662-11e3-952c-61812ab60f67.jpg\\\", stdout, 'binary');\\n    });\\n});\\n</code></pre>\\n\\n<p>I get the following:</p>\\n\\n<p>I've already checked that the folder thumbnail/ exists, and that the image exists. Do you know what else could be going on? </p>\\n\\n<pre><code>/Users/ik/Dropbox/snapgram/public/photos/4af1e720-a662-11e3-952c-61812ab60f67.jpg\\n\\nevents.js:72\\n    throw er; // Unhandled 'error' event\\n          ^\\nError: write EPIPE\\n    at errnoException (net.js:904:11)\\n    at Object.afterWrite (net.js:720:19)\\ncomputername:snapgram ik$ \\n</code></pre>\\n\",\n          \"<p>Trying to deploy my first portal .</p>\\n\\n<p>I am getting 502 gateway timeout error in browser when i was sending the request through browser  </p>\\n\\n<p>when i checked the logs , i got this error</p>\\n\\n<pre><code> 2014/02/03 09:00:32 [error] 16607#0: *1 connect() failed (111: Connection refused) while connecting to upstream, client: 14.159.131.19, server: foo.com, request: \\\"GET HTTP/1.1\\\", upstream: \\\"fastcgi://127.0.0.1:9000\\\", host: \\\"22.11.180.154\\\"\\n</code></pre>\\n\\n<p>is there any problem related to permissions</p>\\n\",\n          \"<p>I want to apply my custom function (it uses an if-else ladder) to these six columns (<code>ERI_Hispanic</code>, <code>ERI_AmerInd_AKNatv</code>, <code>ERI_Asian</code>, <code>ERI_Black_Afr.Amer</code>, <code>ERI_HI_PacIsl</code>, <code>ERI_White</code>) in each row of my dataframe.</p>\\n<p>I've tried different methods from other questions but still can't seem to find the right answer for my problem.  The critical piece of this is that if the person is counted as Hispanic they can't be counted as anything else.  Even if they have a &quot;1&quot; in another ethnicity column they still are counted as Hispanic not two or more races.  Similarly, if the sum of all the ERI columns is greater than 1 they are counted as two or more races and can't be counted as a unique ethnicity(except for Hispanic).</p>\\n<p>It's almost like doing a for loop through each row and if each record meets a criterion they are added to one list and eliminated from the original.</p>\\n<p>From the dataframe below I need to calculate a new column based on the following spec in SQL:</p>\\n<p><strong>CRITERIA</strong></p>\\n<pre><code>IF [ERI_Hispanic] = 1 THEN RETURN \\u201cHispanic\\u201d\\nELSE IF SUM([ERI_AmerInd_AKNatv] + [ERI_Asian] + [ERI_Black_Afr.Amer] + [ERI_HI_PacIsl] + [ERI_White]) &gt; 1 THEN RETURN \\u201cTwo or More\\u201d\\nELSE IF [ERI_AmerInd_AKNatv] = 1 THEN RETURN \\u201cA/I AK Native\\u201d\\nELSE IF [ERI_Asian] = 1 THEN RETURN \\u201cAsian\\u201d\\nELSE IF [ERI_Black_Afr.Amer] = 1 THEN RETURN \\u201cBlack/AA\\u201d\\nELSE IF [ERI_HI_PacIsl] = 1 THEN RETURN \\u201cHaw/Pac Isl.\\u201d\\nELSE IF [ERI_White] = 1 THEN RETURN \\u201cWhite\\u201d\\n</code></pre>\\n<p>Comment: If the ERI Flag for Hispanic is True (1), the employee is classified as \\u201cHispanic\\u201d</p>\\n<p>Comment: If more than 1 non-Hispanic ERI Flag is true, return \\u201cTwo or More\\u201d</p>\\n<p><strong>DATAFRAME</strong></p>\\n<pre><code>     lname          fname       rno_cd  eri_afr_amer    eri_asian   eri_hawaiian    eri_hispanic    eri_nat_amer    eri_white   rno_defined\\n0    MOST           JEFF        E       0               0           0               0               0               1           White\\n1    CRUISE         TOM         E       0               0           0               1               0               0           White\\n2    DEPP           JOHNNY              0               0           0               0               0               1           Unknown\\n3    DICAP          LEO                 0               0           0               0               0               1           Unknown\\n4    BRANDO         MARLON      E       0               0           0               0               0               0           White\\n5    HANKS          TOM         0                       0           0               0               0               1           Unknown\\n6    DENIRO         ROBERT      E       0               1           0               0               0               1           White\\n7    PACINO         AL          E       0               0           0               0               0               1           White\\n8    WILLIAMS       ROBIN       E       0               0           1               0               0               0           White\\n9    EASTWOOD       CLINT       E       0               0           0               0               0               1           White\\n</code></pre>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33577,\n        \"samples\": [\n          \"<json><hibernate><spring-mvc><jpa><jackson>\",\n          \"<bash><command-line><awk><sed><cut>\",\n          \"<c#><asp.net-core><.net-core><x509certificate><x509certificate2>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CreationDate\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 35014,\n        \"samples\": [\n          \"2020-06-05 15:28:14\",\n          \"2015-02-08 23:38:10\",\n          \"2018-06-06 21:02:52\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AnswerCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 76,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          50,\n          54,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ViewCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94829,\n        \"min\": 10001,\n        \"max\": 3486189,\n        \"num_unique_values\": 26730,\n        \"samples\": [\n          59983,\n          18615,\n          52139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83,\n        \"min\": 11,\n        \"max\": 5294,\n        \"num_unique_values\": 550,\n        \"samples\": [\n          381,\n          83,\n          444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création des DataFrame\n",
        "df_cleaned = pd.read_csv(\"/content/drive/MyDrive/2_Formations/2.0_OpenClassRooms/2.0.0_IML/IML P5/5.1_Data/df_cleaned.csv\",\n",
        "                 sep=';')\n",
        "df_cleaned.sample(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "eKeemL7qQCn9",
        "outputId": "f5835c1a-aa05-48b3-f69d-0f758c0f61bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Title  \\\n",
              "4747  How to annotate function that takes a tuple of...   \n",
              "\n",
              "                                                   Body  \\\n",
              "4747  <p>I have a function that takes a tuple of dif...   \n",
              "\n",
              "                                                   Tags  \\\n",
              "4747  <python><python-3.x><type-hinting><mypy><pytho...   \n",
              "\n",
              "                                      lemmatized_corpus  \\\n",
              "4747  ['annotate', 'function', 'take', 'tuple', 'var...   \n",
              "\n",
              "                                        lemmatized_tags  \\\n",
              "4747  ['python', 'python', 'type', 'hinting', 'mypy'...   \n",
              "\n",
              "                                         stemmed_corpus  \\\n",
              "4747  ['annot', 'function', 'take', 'tupl', 'variabl...   \n",
              "\n",
              "                                           stemmed_tags  \n",
              "4747  ['python', 'python', 'type', 'hint', 'mypi', '...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f0eefe2-0e30-4863-98aa-95cdef5379d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_corpus</th>\n",
              "      <th>lemmatized_tags</th>\n",
              "      <th>stemmed_corpus</th>\n",
              "      <th>stemmed_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>How to annotate function that takes a tuple of...</td>\n",
              "      <td>&lt;p&gt;I have a function that takes a tuple of dif...</td>\n",
              "      <td>&lt;python&gt;&lt;python-3.x&gt;&lt;type-hinting&gt;&lt;mypy&gt;&lt;pytho...</td>\n",
              "      <td>['annotate', 'function', 'take', 'tuple', 'var...</td>\n",
              "      <td>['python', 'python', 'type', 'hinting', 'mypy'...</td>\n",
              "      <td>['annot', 'function', 'take', 'tupl', 'variabl...</td>\n",
              "      <td>['python', 'python', 'type', 'hint', 'mypi', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f0eefe2-0e30-4863-98aa-95cdef5379d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f0eefe2-0e30-4863-98aa-95cdef5379d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f0eefe2-0e30-4863-98aa-95cdef5379d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_cleaned\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"How to annotate function that takes a tuple of variable length? (variadic tuple type annotation)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<p>I have a function that takes a tuple of different lengths as an argument:</p>\\n\\n<pre><code>from typing import Tuple\\n\\n\\ndef process_tuple(t: Tuple[str]):\\n    # Do nasty tuple stuff\\n\\nprocess_tuple((\\\"a\\\",))\\nprocess_tuple((\\\"a\\\", \\\"b\\\"))\\nprocess_tuple((\\\"a\\\", \\\"b\\\", \\\"c\\\"))\\n\\n</code></pre>\\n\\n<p>When I annotate function like mentioned above, I get these error messages</p>\\n\\n<pre><code>fool.py:9: error: Argument 1 to \\\"process_tuple\\\" has incompatible type \\\"Tuple[str, str]\\\"; expected \\\"Tuple[str]\\\"\\nfool.py:10: error: Argument 1 to \\\"process_tuple\\\" has incompatible type \\\"Tuple[str, str, str]\\\"; expected \\\"Tuple[str]\\\"\\n</code></pre>\\n\\n<p><code>process_tuple</code> really works with tuples and I use them as immutable lists of variable length. I haven't found any consensus on this topic on the internet, so I wonder how should I annotate this kind of input. </p>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<python><python-3.x><type-hinting><mypy><python-typing>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_corpus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"['annotate', 'function', 'take', 'tuple', 'variable', 'length', 'variadic', 'tuple', 'type', 'annotation', 'function', 'take', 'tuple', 'different', 'length', 'argument', 'typing', 'import', 'tuple', 'process', 'tuple', 'tuple', 'nasty', 'tuple', 'stuff', 'process', 'tuple', 'process', 'tuple', 'process', 'tuple', 'annotate', 'function', 'like', 'mentioned', 'error', 'message', 'fool', 'error', 'argument', 'process', 'tuple', 'incompatible', 'type', 'tuple', 'expected', 'tuple', 'fool', 'error', 'argument', 'process', 'tuple', 'incompatible', 'type', 'tuple', 'expected', 'tuple', 'process', 'tuple', 'really', 'work', 'tuples', 'immutable', 'list', 'variable', 'length', 'found', 'consensus', 'topic', 'internet', 'wonder', 'annotate', 'kind', 'input']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"['python', 'python', 'type', 'hinting', 'mypy', 'python', 'typing']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_corpus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"['annot', 'function', 'take', 'tupl', 'variabl', 'length', 'variad', 'tupl', 'type', 'annot', 'function', 'take', 'tupl', 'differ', 'length', 'argument', 'type', 'import', 'tupl', 'process', 'tupl', 'tupl', 'nasti', 'tupl', 'stuff', 'process', 'tupl', 'process', 'tupl', 'process', 'tupl', 'annot', 'function', 'like', 'mention', 'error', 'messag', 'fool', 'error', 'argument', 'process', 'tupl', 'incompat', 'type', 'tupl', 'expect', 'tupl', 'fool', 'error', 'argument', 'process', 'tupl', 'incompat', 'type', 'tupl', 'expect', 'tupl', 'process', 'tupl', 'realli', 'work', 'tupl', 'immut', 'list', 'variabl', 'length', 'found', 'consensu', 'topic', 'internet', 'wonder', 'annot', 'kind', 'input']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"['python', 'python', 'type', 'hint', 'mypi', 'python', 'type']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "df_cleaned['lemmatized_corpus'] = df_cleaned['lemmatized_corpus'].map(\n",
        "    lambda x: ast.literal_eval(x)\n",
        ")\n",
        "df_cleaned['lemmatized_tags'] = df_cleaned['lemmatized_tags'].map(\n",
        "    lambda x: ast.literal_eval(x)\n",
        ")\n",
        "df_cleaned['stemmed_corpus'] = df_cleaned['stemmed_corpus'].map(\n",
        "    lambda x: ast.literal_eval(x)\n",
        ")\n",
        "df_cleaned['stemmed_tags'] = df_cleaned['stemmed_tags'].map(\n",
        "    lambda x: ast.literal_eval(x)\n",
        ")"
      ],
      "metadata": {
        "id": "6eZ3AibSU0qH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.sample(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "xv_tKAWhU0nk",
        "outputId": "25d0e77a-b6e8-4f58-f006-fb132e898cc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Title  \\\n",
              "27203  Jenkins proxy 407 error   \n",
              "\n",
              "                                                    Body  \\\n",
              "27203  <p>I'm running <strong>Jenkins CI</strong> ins...   \n",
              "\n",
              "                                       Tags  \\\n",
              "27203  <java><apache><jenkins><proxy><ntlm>   \n",
              "\n",
              "                                       lemmatized_corpus  \\\n",
              "27203  [jenkins, proxy, errori, running, jenkins, ins...   \n",
              "\n",
              "                            lemmatized_tags  \\\n",
              "27203  [java, apache, jenkins, proxy, ntlm]   \n",
              "\n",
              "                                          stemmed_corpus  \\\n",
              "27203  [jenkin, proxi, errori, run, jenkin, insid, co...   \n",
              "\n",
              "                             stemmed_tags  \n",
              "27203  [java, apach, jenkin, proxi, ntlm]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94e90031-e6a3-44f7-8f50-638924d8275b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_corpus</th>\n",
              "      <th>lemmatized_tags</th>\n",
              "      <th>stemmed_corpus</th>\n",
              "      <th>stemmed_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27203</th>\n",
              "      <td>Jenkins proxy 407 error</td>\n",
              "      <td>&lt;p&gt;I'm running &lt;strong&gt;Jenkins CI&lt;/strong&gt; ins...</td>\n",
              "      <td>&lt;java&gt;&lt;apache&gt;&lt;jenkins&gt;&lt;proxy&gt;&lt;ntlm&gt;</td>\n",
              "      <td>[jenkins, proxy, errori, running, jenkins, ins...</td>\n",
              "      <td>[java, apache, jenkins, proxy, ntlm]</td>\n",
              "      <td>[jenkin, proxi, errori, run, jenkin, insid, co...</td>\n",
              "      <td>[java, apach, jenkin, proxi, ntlm]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94e90031-e6a3-44f7-8f50-638924d8275b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94e90031-e6a3-44f7-8f50-638924d8275b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94e90031-e6a3-44f7-8f50-638924d8275b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_cleaned\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Jenkins proxy 407 error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<p>I'm running <strong>Jenkins CI</strong> inside a corporate network which uses a proxy for internet access.</p>\\n\\n<p>I tried to configure proxy details in <em>Plugins->Advanced</em>, but even though the credentials are correct (yeah, I checked it a bunch of times), it cannot validate \\\"Test URL\\\" even on <a href=\\\"http://google.com\\\">http://google.com</a> and returns</p>\\n\\n<blockquote>\\n  <p>Failed to connect to <a href=\\\"http://google.com\\\">http://google.com</a> (code 407).</p>\\n</blockquote>\\n\\n<p>Strangely, Jenkins is still able to download plugins itself (whoa!), but totally unable to connect to any HTTP resource. The message that outputs from the console is:</p>\\n\\n<blockquote>\\n  <p>\\u2190[0mApr 16, 2015 1:58:56 PM\\n  org.apache.commons.httpclient.HttpMethodDirector pro\\n  cessProxyAuthChallenge INFO: Failure authenticating with NTLM @proxyrye.asg.com:80 Apr 16, 2015 2:09:09 PM\\n  org.apache.commons.httpclient.HttpMethodDirector execute WithRetry\\n  INFO: I/O exception (java.net.ConnectException) caught when processing\\n  request: Connection timed out: connect Apr 16, 2015 2:09:09 PM\\n  org.apache.commons.httpclient.HttpMethodDirector execute WithRetry\\n  INFO: Retrying request Apr 16, 2015 2:09:10 PM\\n  org.apache.commons.httpclient.auth.AuthChallengeProcesso r\\n  selectAuthScheme INFO: ntlm authentication scheme selected \\u2190[31mApr\\n  16, 2015 2:09:10 PM org.apache.commons.httpclient.HttpMethodDirector\\n  au thenticate SEVERE: Credentials cannot be used for NTLM\\n  authentication: org.apache.commons.h\\n  ttpclient.UsernamePasswordCredentials\\n  org.apache.commons.httpclient.auth.InvalidCredentialsException:\\n  Credentials cann ot be used for NTLM authentication:\\n  org.apache.commons.httpclient.UsernamePasswo rdCredentials\\n          at org.apache.commons.httpclient.auth.NTLMScheme.authenticate(NTLMScheme\\n  .java:332)</p>\\n</blockquote>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<java><apache><jenkins><proxy><ntlm>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_corpus\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_corpus\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9v0xueXU0k0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "rQMioxiOsKjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning\n",
        "https://towardsdatascience.com/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db"
      ],
      "metadata": {
        "id": "FOxGukV8ujl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_cleaned.copy()"
      ],
      "metadata": {
        "id": "a3L6pptdulEJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial"
      ],
      "metadata": {
        "id": "598timMhsMLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "04CreWA5QQsJ",
        "outputId": "45ff251d-5a71-408d-d9d2-5f8760353c5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Title  \\\n",
              "0  Python kernel dies for second run of PyQt5 GUI   \n",
              "\n",
              "                                                Body  \\\n",
              "0  <ul>\\n<li>Using Spyder in Python 3.5.2 |Anacon...   \n",
              "\n",
              "                                         Tags  \\\n",
              "0  <python><ipython><anaconda><pyqt5><spyder>   \n",
              "\n",
              "                                   lemmatized_corpus  \\\n",
              "0  [python, kernel, dy, second, pyqt, using, spyd...   \n",
              "\n",
              "                             lemmatized_tags  \\\n",
              "0  [python, ipython, anaconda, pyqt, spyder]   \n",
              "\n",
              "                                      stemmed_corpus  \\\n",
              "0  [python, kernel, dy, second, pyqt, use, spyder...   \n",
              "\n",
              "                                stemmed_tags  \n",
              "0  [python, ipython, anaconda, pyqt, spyder]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-000facb3-11e0-4f18-8d2c-2223c30484a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>lemmatized_corpus</th>\n",
              "      <th>lemmatized_tags</th>\n",
              "      <th>stemmed_corpus</th>\n",
              "      <th>stemmed_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Python kernel dies for second run of PyQt5 GUI</td>\n",
              "      <td>&lt;ul&gt;\\n&lt;li&gt;Using Spyder in Python 3.5.2 |Anacon...</td>\n",
              "      <td>&lt;python&gt;&lt;ipython&gt;&lt;anaconda&gt;&lt;pyqt5&gt;&lt;spyder&gt;</td>\n",
              "      <td>[python, kernel, dy, second, pyqt, using, spyd...</td>\n",
              "      <td>[python, ipython, anaconda, pyqt, spyder]</td>\n",
              "      <td>[python, kernel, dy, second, pyqt, use, spyder...</td>\n",
              "      <td>[python, ipython, anaconda, pyqt, spyder]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-000facb3-11e0-4f18-8d2c-2223c30484a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-000facb3-11e0-4f18-8d2c-2223c30484a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-000facb3-11e0-4f18-8d2c-2223c30484a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 29995,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29995,\n        \"samples\": [\n          \"Class 'League\\\\Flysystem\\\\AwsS3v3\\\\AwsS3Adapter' not found (Laravel + Heroku)\",\n          \"How to update OpenSSL on mac?\",\n          \"Bigquery - json_extract all elements from an array\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29995,\n        \"samples\": [\n          \"<p>connect my laravel 5.4 application in heroku with aws s3 to save and display images that I upload with a dashboard. </p>\\n\\n<p>In local I have no problem with uploading and viewing the images, even these are stored in the bucket I made. But when I set up aws in heroku to do tests there, I get the error: <strong>Class 'League\\\\Flysystem\\\\AwsS3v3\\\\AwsS3Adapter'</strong> </p>\\n\\n<p>I already removed and reinstalled the package from composer, I do not know why the error does not appear in my local environment.</p>\\n\\n<p>thank you very much.</p>\\n\",\n          \"<p>I need to ensure that I have OpenSSL version of 1.0.1 or greater to connect to the Salesforce API according to <a href=\\\"https://github.com/superfell/Beatbox\\\" rel=\\\"nofollow noreferrer\\\">this documentation</a>. </p>\\n\\n<p>According to <a href=\\\"https://apple.stackexchange.com/questions/126830/how-to-upgrade-openssl-in-os-x\\\">this question</a>, I can do the following steps (which I've completed successfully)</p>\\n\\n<ol>\\n<li>brew update </li>\\n<li>brew install openssl</li>\\n<li>brew link --force openssl</li>\\n</ol>\\n\\n<p>When I run <code>openssl version -a</code>, I get the following: </p>\\n\\n<pre><code>OpenSSL 1.0.2h  3 May 2016\\nbuilt on: reproducible build, date unspecified\\nplatform: darwin64-x86_64-cc\\noptions:  bn(64,64) rc4(ptr,int) des(idx,cisc,16,int) idea(int) blowfish(idx) \\ncompiler: /usr/bin/clang -I. -I.. -I../include  -fPIC -fno-common -DOPENSSL_PIC -DZLIB -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -arch x86_64 -O3 -DL_ENDIAN -Wall -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM -DECP_NISTZ256_ASM\\nOPENSSLDIR: \\\"/opt/local/etc/openssl\\\"\\n</code></pre>\\n\\n<p>However, when I run <code>python -c \\\"import ssl; print ssl.OPENSSL_VERSION\\\"</code>, I get the following: </p>\\n\\n<pre><code>OpenSSL 0.9.8zh 14 Jan 2016\\n</code></pre>\\n\\n<p>I'm getting mixed signals from my computer, but my salesforce module is still not working, so I know OpenSSL is not updated completely on my computer. </p>\\n\\n<p>I should also mention that I've also tried: </p>\\n\\n<pre><code>sudo port upgrade openssl\\n</code></pre>\\n\\n<p>Port seemed to have worked, but when I run <code>python -c \\\"import ssl; print ssl.OPENSSL_VERSION\\\"</code> I still get that I'm on \\\"OpenSSL 0.9.8zh\\\"</p>\\n\\n<p>Is there another way to update OpenSSL?</p>\\n\",\n          \"<p>i'm trying to extract two key from every json in an arry of jsons(using sql legacy)\\ncurrently i am using json extract function :</p>\\n\\n<pre><code>json_extract(json_column , '$[1].X') AS X,\\njson_extract(json_column , '$[1].Y') AS Y,\\n</code></pre>\\n\\n<p>how can i make it run on every json at the 'json arry column', and not just [1] (for example)?</p>\\n\\n<p>An example json:</p>\\n\\n<pre><code>[\\n\\n{\\\"blabla\\\":000,\\\"X\\\":1,\\\"blabla\\\":000,\\\"blabla\\\":000,\\\"blabla\\\":000,,\\\"Y\\\":\\\"2\\\"},\\n\\n{\\\"blabla\\\":000,\\\"X\\\":3,\\\"blabla\\\":000,\\\"blabla\\\":000,\\\"blabla\\\":000,,\\\"Y\\\":\\\"4\\\"},\\n\\n]   \\n</code></pre>\\n\\n<p>thanks in advance!</p>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28642,\n        \"samples\": [\n          \"<java><xml><jaxb><marshalling><unmarshalling>\",\n          \"<c#><asp.net-core><xamarin><ssl-certificate><maui>\",\n          \"<android><gradle><android-gradle-plugin><apk><keystore>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_corpus\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_corpus\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['lemmatized_corpus'].notnull()]"
      ],
      "metadata": {
        "id": "12UZfr4WtIdQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_texts = df['lemmatized_corpus'].to_list()"
      ],
      "metadata": {
        "id": "ORj907RLsZQ-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "binMHTBBr8RN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "uWzbC9ahsc3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbb484f-156d-48c6-a3e9-034383a5c1ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=142364, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(min_count=100,\n",
        "                     window=2,\n",
        "                     #size=300,\n",
        "                     sample=6e-5,\n",
        "                     alpha=0.03,\n",
        "                     min_alpha=0.0007,\n",
        "                     negative=20,\n",
        "                     )"
      ],
      "metadata": {
        "id": "QKjSzGS7Ybdw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df['lemmatized_corpus'].to_list()"
      ],
      "metadata": {
        "id": "dS9H1pkYcKfm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54S2oyJCcIJX",
        "outputId": "2599d8fa-f086-4dc9-a646-175fb088925f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 812 ms, sys: 4 ms, total: 816 ms\n",
            "Wall time: 819 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BNA1TWJcdjr",
        "outputId": "f661f137-9015-48da-a580-613d6279dfcc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 8s, sys: 1.24 s, total: 4min 9s\n",
            "Wall time: 2min 28s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40421014, 112815480)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As we do not plan to train the model any further, we are calling init_sims(), which will make the model much more memory-efficient:\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-oYbx37cnJK",
        "outputId": "7aed3085-8a97-44e6-c3a8-30d92ee1fab4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-97433d54265c>:2: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  w2v_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"python\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BdA4o5kc0Fz",
        "outputId": "38b88a2a-83ef-4de5-cf02-1a8e85090b2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('site', 0.7436580061912537),\n",
              " ('anaconda', 0.7122657299041748),\n",
              " ('venv', 0.6700139045715332),\n",
              " ('local', 0.6625819206237793),\n",
              " ('tensorflow', 0.6613535284996033),\n",
              " ('package', 0.6484872102737427),\n",
              " ('line', 0.6331347227096558),\n",
              " ('virtualenv', 0.6294698119163513),\n",
              " ('envs', 0.6144281625747681),\n",
              " ('pyenv', 0.6059690713882446)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USE"
      ],
      "metadata": {
        "id": "5RLhhK6ofpzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load pre-trained universal sentence encoder model\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Sentences for which you want to create embeddings,\n",
        "# passed as an array in embed()\n",
        "Sentences = df['lemmatized_corpus'].to_list()\n",
        "\n",
        "embeddings = embed(Sentences)\n",
        "\n",
        "# Printing embeddings of each sentence\n",
        "print(embeddings)\n",
        "\n",
        "# To print each embeddings along with its corresponding\n",
        "# sentence below code can be used.\n",
        "for i in range(len(Sentences)):\n",
        "    print(Sentences[i])\n",
        "    print(embeddings[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9jB4zgvzdUe-",
        "outputId": "7c3ba6d7-1bcf-420f-930c-8acb00830b35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-688c3cca2920>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load pre-trained universal sentence encoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m             present=tf.__version__))\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0m_ensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m_ensure_tf_install\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m   \"\"\"\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Print more informative error message, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masserts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# for some specializations of the operator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional_expressions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mif_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_flow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfor_stmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_flow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mif_stmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/conditional_expressions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_cond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_builtins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/py_builtins.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_assert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_parsing_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcond_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunc_graph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc_graph_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mindexed_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnone_tensor\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0m_ReuseMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m   \u001b[0;34m\"\"\"Mode for variable access within a variable scope.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/enum.py\u001b[0m in \u001b[0;36m__prepare__\u001b[0;34m(metacls, cls, bases, **kwds)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__prepare__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetacls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# check that previous enum members do not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mmetacls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_existing_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;31m# create the namespace dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0menum_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EnumDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/enum.py\u001b[0m in \u001b[0;36m_check_for_existing_members\u001b[0;34m(class_name, bases)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mro__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_names_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                     raise TypeError(\n\u001b[1;32m    575\u001b[0m                             \u001b[0;34m\"%s: cannot extend enumeration %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "id": "qhiyl5v-gJcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2a5fF91rh92w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}